"""
æ¨¡å‹APIè°ƒç”¨æ¨¡å—
æ”¯æŒè°ƒç”¨å„ç§è§†è§‰è¯­è¨€æ¨¡å‹çš„API
"""
import os
import sys
import base64
import time
import logging
import re
import json
import io
from pathlib import Path
from typing import Optional, Dict, Any, Tuple, List

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from openai import OpenAI
from .config import API_CONFIG, EVAL_CONFIG

# å°è¯•å¯¼å…¥PIL/Pillowç”¨äºå›¾ç‰‡å‹ç¼©
try:
    from PIL import Image
    PIL_AVAILABLE = True
except ImportError:
    PIL_AVAILABLE = False
    logging.warning("PIL/Pillowæœªå®‰è£…ï¼Œå›¾ç‰‡å‹ç¼©åŠŸèƒ½å°†ä¸å¯ç”¨ã€‚å»ºè®®å®‰è£…: pip install Pillow")


def compress_image(image_path: str, max_longest_side: int = 1600, quality: int = 92, force_jpeg: bool = False) -> bytes:
    """
    æ™ºèƒ½å›¾åƒå‹ç¼©å·¥å…· - ä¸“ä¸ºå¤šæ¨¡æ€å¤§æ¨¡å‹å¤šå›¾è¾“å…¥è®¾è®¡
    
    é‡è¦è§„åˆ™ï¼š
    1. åˆ†è¾¨ç‡å®šä¹‰ä¸º"æœ€é•¿è¾¹ (Max Edge)"ï¼Œè€Œéå›ºå®šå®½é«˜
    2. å°å›¾ä¸è¦æ”¾å¤§ï¼šå¦‚æœåŸå›¾æœ€é•¿è¾¹ <= max_longest_sideï¼Œä¿æŒåŸå°ºå¯¸ï¼Œä¸æ”¾å¤§
    3. å¤§å›¾æŒ‰æ¯”ä¾‹ç¼©å°ï¼šå¦‚æœåŸå›¾æœ€é•¿è¾¹ > max_longest_sideï¼Œä¿æŒå®½é«˜æ¯”ç¼©æ”¾ï¼Œä½¿å¾— max(w, h) <= max_longest_side
    
    Args:
        image_path: å›¾ç‰‡è·¯å¾„
        max_longest_side: æœ€é•¿è¾¹çš„æœ€å¤§åƒç´ å€¼ï¼Œé»˜è®¤ 1600ï¼ˆèŒƒå›´å»ºè®® 1280-1600ï¼‰
        quality: JPEGè´¨é‡ï¼ˆ1-100ï¼‰ï¼Œé»˜è®¤92ï¼Œå½“force_jpeg=Trueæ—¶ä½¿ç”¨æ­¤å‚æ•°
        force_jpeg: æ˜¯å¦å¼ºåˆ¶è¾“å‡ºJPEGæ ¼å¼ï¼ˆå¤šå›¾åœºæ™¯æ¨èä½¿ç”¨ï¼‰ï¼Œé»˜è®¤False
        
    Returns:
        å‹ç¼©åçš„å›¾ç‰‡å­—èŠ‚æ•°æ®
    """
    if not PIL_AVAILABLE:
        # å¦‚æœPILä¸å¯ç”¨ï¼Œç›´æ¥è¯»å–åŸå›¾
        with open(image_path, "rb") as f:
            return f.read()
    
    try:
        # 1. è¯»å–å›¾ç‰‡
        if isinstance(image_path, str):
            if not os.path.exists(image_path):
                logging.warning(f"Warning: Image not found {image_path}")
                return b""
            img = Image.open(image_path)
        else:
            img = image_path
        
        original_width, original_height = img.size
        original_longest_side = max(original_width, original_height)
        
        # 2. å¤„ç†é€æ˜é€šé“ (RGBA/P -> RGB)
        # å¾ˆå¤šå›¾è¡¨æ˜¯é€æ˜åº• PNGï¼Œç›´æ¥è½¬ JPG ä¼šå˜å…¨é»‘ï¼Œå¿…é¡»å¡«å……ç™½è‰²èƒŒæ™¯
        if img.mode in ('RGBA', 'LA') or (img.mode == 'P' and 'transparency' in img.info):
            background = Image.new('RGB', img.size, (255, 255, 255))
            if img.mode == 'P':
                img = img.convert('RGBA')
            background.paste(img, mask=img.split()[-1])
            img = background
        elif img.mode != 'RGB':
            img = img.convert('RGB')
        
        # 3. æ™ºèƒ½ç¼©æ”¾ (Lanczos ç®—æ³•)
        longest_side = max(img.size)
        
        # åªæœ‰å½“åŸå›¾ > ç›®æ ‡å°ºå¯¸æ—¶æ‰ç¼©å°ï¼Œåšå†³ä¸æ”¾å¤§
        if longest_side > max_longest_side:
            ratio = max_longest_side / longest_side
            new_width = int(original_width * ratio)
            new_height = int(original_height * ratio)
            # æ ¸å¿ƒï¼šä½¿ç”¨ LANCZOS æ»¤é•œï¼Œç¡®ä¿æ–‡å­—é”åˆ©
            img = img.resize((new_width, new_height), Image.Resampling.LANCZOS)
            logging.info(f"ğŸ–¼ï¸ å›¾ç‰‡å‹ç¼©: {os.path.basename(image_path) if isinstance(image_path, str) else 'Image'} åŸå°ºå¯¸ {original_width}x{original_height} (æœ€é•¿è¾¹={original_longest_side}px) -> å‹ç¼©åˆ° {new_width}x{new_height} (æœ€é•¿è¾¹={max_longest_side}px)")
        else:
            logging.info(f"ğŸ–¼ï¸ å›¾ç‰‡å‹ç¼©: {os.path.basename(image_path) if isinstance(image_path, str) else 'Image'} åŸå°ºå¯¸ {original_width}x{original_height} (æœ€é•¿è¾¹={original_longest_side}px) <= {max_longest_side}pxï¼Œä¿æŒåŸå°ºå¯¸ï¼ˆæ— éœ€å‹ç¼©ï¼‰")
        
        # 4. å¯¼å‡ºä¸ºé«˜ç”»è´¨ JPEGï¼ˆå½“force_jpeg=Trueæ—¶ï¼‰æˆ–æ ¹æ®åŸæ ¼å¼
        output = io.BytesIO()
        if force_jpeg:
            # å¼ºåˆ¶ä½¿ç”¨JPEGæ ¼å¼ï¼ˆå¤šå›¾åœºæ™¯æ¨èï¼‰
            img.save(output, format="JPEG", quality=quality, optimize=True)
        else:
            # æ ¹æ®åŸå›¾æ ¼å¼é€‰æ‹©ä¿å­˜æ ¼å¼ï¼ˆå…¼å®¹æ—§é€»è¾‘ï¼‰
            format_ext = Path(image_path).suffix.lower() if isinstance(image_path, str) else '.jpg'
            if format_ext in ['.jpg', '.jpeg']:
                img.save(output, format='JPEG', quality=quality, optimize=True)
            elif format_ext == '.png':
                # PNGæ ¼å¼ä½¿ç”¨optimizeå‚æ•°ï¼Œä¿æŒåŸæ ¼å¼
                img.save(output, format='PNG', optimize=True)
            else:
                # å…¶ä»–æ ¼å¼è½¬æ¢ä¸ºJPEG
                img.save(output, format='JPEG', quality=quality, optimize=True)
        
        output.seek(0)
        return output.read()
        
    except Exception as e:
        logging.warning(f"å›¾ç‰‡å‹ç¼©å¤±è´¥ {image_path}: {e}ï¼Œä½¿ç”¨åŸå›¾")
        # å‹ç¼©å¤±è´¥æ—¶è¿”å›åŸå›¾
        try:
            if isinstance(image_path, str):
                with open(image_path, "rb") as f:
                    return f.read()
            else:
                return b""
        except:
            return b""


def encode_image(image_path: str, compress: bool = False, max_longest_side: int = 1600, quality: int = 92) -> str:
    """
    å°†å›¾ç‰‡ç¼–ç ä¸º base64
    
    Args:
        image_path: å›¾ç‰‡è·¯å¾„
        compress: æ˜¯å¦å‹ç¼©å›¾ç‰‡ï¼Œé»˜è®¤False
        max_longest_side: å‹ç¼©æ—¶çš„æœ€é•¿è¾¹æœ€å¤§åƒç´ å€¼ï¼Œé»˜è®¤ 1600ï¼ˆèŒƒå›´å»ºè®® 1280-1600ï¼‰
        quality: JPEGè´¨é‡ï¼ˆ1-100ï¼‰ï¼Œé»˜è®¤92ï¼Œä»…å¯¹JPEGæ ¼å¼æœ‰æ•ˆ
        
    Returns:
        base64 ç¼–ç çš„å›¾ç‰‡å­—ç¬¦ä¸²
    """
    if compress:
        # å‹ç¼©æ—¶å¼ºåˆ¶ä½¿ç”¨JPEGæ ¼å¼
        force_jpeg = True
        image_data = compress_image(image_path, max_longest_side=max_longest_side, quality=quality, force_jpeg=force_jpeg)
        logging.debug(f"âœ… å›¾ç‰‡å‹ç¼©å®Œæˆ: {os.path.basename(image_path)}, å‹ç¼©åå¤§å°={len(image_data)} bytes")
    else:
        with open(image_path, "rb") as image_file:
            image_data = image_file.read()
        logging.debug(f"â­ï¸ è·³è¿‡å‹ç¼©: {os.path.basename(image_path)}, ä½¿ç”¨åŸå›¾ (å¤§å°={len(image_data)} bytes)")
    
    return base64.b64encode(image_data).decode('utf-8')


def get_image_format(image_path: str) -> str:
    """
    è·å–å›¾ç‰‡æ ¼å¼ï¼ˆç”¨äº data URIï¼‰
    
    Args:
        image_path: å›¾ç‰‡è·¯å¾„
        
    Returns:
        å›¾ç‰‡æ ¼å¼ï¼ˆå¦‚ jpeg, pngï¼‰
    """
    suffix = Path(image_path).suffix.lower().replace('.', '')
    if suffix == 'jpg':
        return 'jpeg'
    return suffix if suffix in ['jpeg', 'png', 'webp', 'gif'] else 'jpeg'


def estimate_text_tokens(text: str) -> int:
    """
    ä¼°ç®—æ–‡æœ¬çš„tokenæ•°é‡
    ä½¿ç”¨ç®€å•ä¼°ç®—ï¼š1 token â‰ˆ 4 å­—ç¬¦ï¼ˆå¯¹äºä¸­æ–‡å’Œè‹±æ–‡æ··åˆæ–‡æœ¬ï¼‰
    
    Args:
        text: æ–‡æœ¬å†…å®¹
        
    Returns:
        ä¼°ç®—çš„tokenæ•°é‡
    """
    if not text:
        return 0
    # ç®€å•ä¼°ç®—ï¼š1 token â‰ˆ 4 å­—ç¬¦
    # å¯¹äºä¸­æ–‡ï¼Œå¯èƒ½æ›´æ¥è¿‘ 1 token â‰ˆ 1.5 å­—ç¬¦ï¼Œä½†ä¸ºäº†ä¿å®ˆä¼°è®¡ï¼Œä½¿ç”¨ 4 å­—ç¬¦
    return len(text) // 4 + 1


def estimate_image_tokens(image_path: str, width: Optional[int] = None, height: Optional[int] = None) -> int:
    """
    ä¼°ç®—å›¾ç‰‡çš„tokenæ•°é‡ (ä¿®æ­£ç‰ˆï¼šé€‚é… Qwen/Llama Patch æœºåˆ¶)
    
    ä½¿ç”¨ Qwen/Llama Vision Patch æœºåˆ¶ï¼š
    - Patch size é€šå¸¸æ˜¯ 14x14
    - Tokenæ•° = (H/14) * (W/14) + overhead
    - è¿™æ˜¯ Qwen/Llama ç­‰å¼€æºæ¨¡å‹çš„çœŸå®æ¶ˆè€—é€»è¾‘
    
    Args:
        image_path: å›¾ç‰‡è·¯å¾„
        width: å›¾ç‰‡å®½åº¦ï¼ˆå¯é€‰ï¼Œå¦‚æœä¸æä¾›åˆ™ä»æ–‡ä»¶è¯»å–ï¼‰
        height: å›¾ç‰‡é«˜åº¦ï¼ˆå¯é€‰ï¼Œå¦‚æœä¸æä¾›åˆ™ä»æ–‡ä»¶è¯»å–ï¼‰
        
    Returns:
        ä¼°ç®—çš„tokenæ•°é‡
    """
    # å¦‚æœPILä¸å¯ç”¨ï¼Œç»™ä¸€ä¸ªæ¯”è¾ƒå¤§çš„å®‰å…¨å€¼
    if not PIL_AVAILABLE:
        return 2000
    
    try:
        if width is None or height is None:
            with Image.open(image_path) as img:
                width, height = img.size
        
        # Qwen/Llama Vision Patch size é€šå¸¸æ˜¯ 14
        # åŠ ä¸Š ceil å‘ä¸Šå–æ•´ï¼Œä¿è¯ä¼°ç®—ä¸ä¼šåå°
        patches_w = (width + 13) // 14
        patches_h = (height + 13) // 14
        
        # åŸºç¡€ Token æ•°
        base_tokens = patches_w * patches_h
        
        # åŠ ä¸Šç‰¹æ®Šæ ‡è®° Overhead (Vision Start, End ç­‰)ï¼Œç»™ 128 å®‰å…¨ä½™é‡
        return base_tokens + 128

    except Exception as e:
        logging.warning(f"ä¼°ç®—å›¾ç‰‡tokenå¤±è´¥ {image_path}: {e}ï¼Œä½¿ç”¨ä¿å®ˆä¼°ç®—")
        return 2000


def get_image_size(image_path: str) -> Tuple[int, int]:
    """
    è·å–å›¾ç‰‡å°ºå¯¸
    
    Args:
        image_path: å›¾ç‰‡è·¯å¾„
        
    Returns:
        (width, height)
    """
    if not PIL_AVAILABLE:
        return (1024, 1024)  # é»˜è®¤å€¼
    
    try:
        with Image.open(image_path) as img:
            return img.size
    except Exception as e:
        logging.warning(f"è·å–å›¾ç‰‡å°ºå¯¸å¤±è´¥ {image_path}: {e}")
        return (1024, 1024)  # é»˜è®¤å€¼


def _determine_image_compression_settings(
    image_paths: List[str],
    is_multi_round: bool = False
) -> Tuple[bool, int, int]:
    """
    ç¡®å®šå›¾ç‰‡å‹ç¼©è®¾ç½®ï¼ˆæå–çš„å…¬å…±é€»è¾‘ï¼‰
    
    Args:
        image_paths: å›¾ç‰‡è·¯å¾„åˆ—è¡¨
        is_multi_round: æ˜¯å¦æ˜¯å¤šè½®å¯¹è¯ï¼ˆå¤šè½®å¯¹è¯æ—¶å¼ºåˆ¶å‹ç¼©ä»¥èŠ‚çœtokenï¼‰
        
    Returns:
        (should_compress, max_longest_side, quality)
        - should_compress: æ˜¯å¦å¯ç”¨å‹ç¼©
        - max_longest_side: å‹ç¼©åçš„æœ€é•¿è¾¹åƒç´ å€¼
        - quality: JPEGå‹ç¼©è´¨é‡
    """
    if not image_paths:
        return False, 1600, 92
    
    num_images = len(image_paths)
    
    # å‹ç¼©ç­–ç•¥ï¼š
    # 1. å•å›¾å•è½®ï¼šæ ¹æ®é…ç½®å†³å®šæ˜¯å¦å‹ç¼©ï¼ˆé»˜è®¤ä¸å‹ç¼©ï¼Œå¯é€šè¿‡ EVAL_COMPRESS_SINGLE_IMAGE_SINGLE_ROUND ç¯å¢ƒå˜é‡æˆ–é…ç½®å¯ç”¨ï¼‰
    # 2. å•å›¾å¤šè½®ï¼šå‹ç¼©åˆ°1024pxï¼Œè½¬æ¢ä¸ºJPEG
    # 3. å¤šå›¾å•è½®ï¼šå‹ç¼©åˆ°512pxï¼Œè½¬æ¢ä¸ºJPEG
    # 4. å¤šå›¾å¤šè½®ï¼šå‹ç¼©åˆ°512pxï¼Œè½¬æ¢ä¸ºJPEG
    if num_images > 1:
        # å¤šå›¾åœºæ™¯ï¼šå‹ç¼©åˆ°512px
        should_compress = True
        max_longest_side = 512
        quality = 85
        if is_multi_round:
            logging.info(f"ğŸ“¸ å›¾ç‰‡å‹ç¼©ç­–ç•¥: æ£€æµ‹åˆ° {num_images} å¼ å›¾ç‰‡ï¼ˆå¤šå›¾å¤šè½®ï¼‰ï¼Œä½¿ç”¨é…ç½®ï¼ˆ512px, quality=85, JPEGï¼‰")
        else:
            logging.info(f"ğŸ“¸ å›¾ç‰‡å‹ç¼©ç­–ç•¥: æ£€æµ‹åˆ° {num_images} å¼ å›¾ç‰‡ï¼ˆå¤šå›¾å•è½®ï¼‰ï¼Œä½¿ç”¨é…ç½®ï¼ˆ512px, quality=85, JPEGï¼‰")
        return should_compress, max_longest_side, quality
    elif is_multi_round:
        # å•å›¾å¤šè½®ï¼šå‹ç¼©åˆ°1024px
        should_compress = True
        max_longest_side = 1024
        quality = 92
        logging.info(f"ğŸ“¸ å›¾ç‰‡å‹ç¼©ç­–ç•¥: æ£€æµ‹åˆ° 1 å¼ å›¾ç‰‡ï¼ˆå•å›¾å¤šè½®ï¼‰ï¼Œä½¿ç”¨é…ç½®ï¼ˆ1024px, quality=92, JPEGï¼‰")
        return should_compress, max_longest_side, quality
    
    # å•å›¾å•è½®ï¼šæ ¹æ®é…ç½®å†³å®šæ˜¯å¦å‹ç¼©
    should_compress = EVAL_CONFIG.get("compress_single_image_single_round", False)
    max_longest_side = EVAL_CONFIG.get("image_compress_max_longest_side", 1600)
    quality = EVAL_CONFIG.get("image_compress_quality", 92)
    
    if should_compress:
        logging.info(f"ğŸ“¸ å›¾ç‰‡å‹ç¼©ç­–ç•¥: æ£€æµ‹åˆ° 1 å¼ å›¾ç‰‡ï¼ˆå•å›¾å•è½®ï¼‰ï¼Œå·²å¯ç”¨å‹ç¼©ï¼ˆ{max_longest_side}px, quality={quality}, JPEGï¼‰")
    else:
        logging.info(f"ğŸ“¸ å›¾ç‰‡å‹ç¼©ç­–ç•¥: æ£€æµ‹åˆ° 1 å¼ å›¾ç‰‡ï¼ˆå•å›¾å•è½®ï¼‰ï¼Œæœªå¯ç”¨å‹ç¼©ï¼Œä¿æŒåŸå›¾æ ¼å¼å’Œå°ºå¯¸")
    return should_compress, max_longest_side, quality


def call_model_api(
    model_name: str,
    prompt: str = None,
    image_paths: Optional[List[str]] = None,
    max_retries: Optional[int] = None,
    retry_delay: Optional[float] = None,
    messages: Optional[List[Dict[str, Any]]] = None
) -> Tuple[str, float, Dict[str, Any]]:
    """
    è°ƒç”¨æ¨¡å‹API
    
    Args:
        model_name: æ¨¡å‹åç§°ï¼ˆå¯¹åº” API_CONFIG ä¸­çš„ keyï¼‰
        prompt: æç¤ºè¯ï¼ˆå¦‚æœæä¾›äº† messagesï¼Œåˆ™å¿½ç•¥æ­¤å‚æ•°ï¼‰
        image_paths: å›¾ç‰‡è·¯å¾„åˆ—è¡¨ï¼ˆå¯é€‰ï¼Œä»…åœ¨æœªæä¾› messages æ—¶ä½¿ç”¨ï¼‰
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°ï¼ˆé»˜è®¤ä½¿ç”¨é…ç½®ï¼‰
        retry_delay: é‡è¯•å»¶è¿Ÿï¼ˆé»˜è®¤ä½¿ç”¨é…ç½®ï¼‰
        messages: å¯¹è¯å†å²æ¶ˆæ¯åˆ—è¡¨ï¼ˆå¯é€‰ï¼Œæ ¼å¼ï¼š[{"role": "user", "content": ...}, {"role": "assistant", "content": ...}, ...]ï¼‰
                 å¦‚æœæä¾›äº† messagesï¼Œå°†ä½¿ç”¨å®ƒè€Œä¸æ˜¯ prompt å’Œ image_paths
        
    Returns:
        (answer, response_time, raw_response)
        - answer: æ¨¡å‹å›ç­”
        - response_time: å“åº”æ—¶é—´ï¼ˆç§’ï¼‰
        - raw_response: åŸå§‹APIå“åº”ï¼ˆå­—å…¸æ ¼å¼ï¼‰
    """
    if model_name not in API_CONFIG:
        raise ValueError(f"æ¨¡å‹ '{model_name}' ä¸åœ¨ API_CONFIG ä¸­")
    
    api_config = API_CONFIG[model_name]
    max_retries = max_retries or EVAL_CONFIG.get("max_retries", 3)
    retry_delay = retry_delay or EVAL_CONFIG.get("retry_delay", 1)
    
    # è¶…æ—¶æ—¶é—´ï¼šä¼˜å…ˆä½¿ç”¨ EVAL_CONFIG ä¸­çš„ timeoutï¼Œå…¶æ¬¡ä½¿ç”¨æ¨¡å‹é…ç½®ä¸­çš„ timeout
    timeout = EVAL_CONFIG.get("timeout") or api_config.get("timeout", 600)
    
    # åˆ›å»º OpenAI å®¢æˆ·ç«¯ï¼Œtimeout åº”è¯¥åœ¨å®¢æˆ·ç«¯åˆå§‹åŒ–æ—¶è®¾ç½®
    client = OpenAI(
        base_url=api_config["base_url"],
        api_key=api_config["api_key"],
        timeout=timeout
    )
    
    # å¦‚æœæä¾›äº† messagesï¼Œç›´æ¥ä½¿ç”¨ï¼›å¦åˆ™æ„å»ºå•æ¡æ¶ˆæ¯
    if messages is not None:
        # ä½¿ç”¨æä¾›çš„å¯¹è¯å†å²
        # å¦‚æœç¬¬ä¸€æ¡æ¶ˆæ¯æ˜¯ user ä¸”éœ€è¦æ·»åŠ å›¾ç‰‡ï¼Œæ£€æŸ¥æ˜¯å¦å·²ç»åŒ…å«å›¾ç‰‡
        if messages and len(messages) > 0:
            first_msg = messages[0]
            if first_msg.get("role") == "user" and image_paths:
                user_content = first_msg.get("content", [])
                if isinstance(user_content, str):
                    user_content = [{"type": "text", "text": user_content}]
                elif not isinstance(user_content, list):
                    user_content = []
                
                # æ£€æŸ¥ç¬¬ä¸€æ¡æ¶ˆæ¯æ˜¯å¦å·²ç»åŒ…å«å›¾ç‰‡ï¼ˆé¿å…é‡å¤æ·»åŠ ï¼‰
                has_image_in_first_msg = any(
                    isinstance(item, dict) and item.get("type") == "image_url"
                    for item in user_content
                )
                
                if not has_image_in_first_msg:
                    # ç¬¬ä¸€æ¡æ¶ˆæ¯ä¸­æ²¡æœ‰å›¾ç‰‡ï¼Œéœ€è¦æ·»åŠ å›¾ç‰‡
                    # ä¼°ç®—æ–‡æœ¬tokenï¼ˆä»æ‰€æœ‰æ¶ˆæ¯ä¸­æå–æ–‡æœ¬ï¼‰
                    text_content = ""
                    for msg in messages:
                        content = msg.get("content", "")
                        if isinstance(content, str):
                            text_content += content
                        elif isinstance(content, list):
                            for item in content:
                                if isinstance(item, dict) and item.get("type") == "text":
                                    text_content += item.get("text", "")
                    
                    # ç¡®å®šå›¾ç‰‡å‹ç¼©è®¾ç½®ï¼ˆä½¿ç”¨å…¬å…±å‡½æ•°ï¼‰
                    # messagesåœºæ™¯é€šå¸¸æ˜¯å¤šè½®å¯¹è¯
                    is_multi_round = len(messages) > 1 or any(msg.get("role") == "assistant" for msg in messages)
                    should_compress, max_longest_side, quality = _determine_image_compression_settings(
                        image_paths=image_paths,
                        is_multi_round=is_multi_round
                    )
                    
                    # æ·»åŠ å›¾ç‰‡åˆ°ç¬¬ä¸€æ¡æ¶ˆæ¯
                    for image_path in image_paths:
                        if image_path.startswith(("http://", "https://")):
                            user_content.append({
                                "type": "image_url",
                                "image_url": {"url": image_path}
                            })
                        elif os.path.exists(image_path):
                            # å¦‚æœå‹ç¼©ï¼Œå¼ºåˆ¶ä½¿ç”¨ JPEG æ ¼å¼ï¼›å¦‚æœä¸å‹ç¼©ï¼Œä¿æŒåŸæ ¼å¼
                            if should_compress:
                                image_format = 'jpeg'
                            else:
                                image_format = get_image_format(image_path)
                            base64_image = encode_image(image_path, compress=should_compress, max_longest_side=max_longest_side, quality=quality)
                            user_content.append({
                                "type": "image_url",
                                "image_url": {"url": f"data:image/{image_format};base64,{base64_image}"}
                            })
                        else:
                            logging.warning(f"å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨æˆ–URLæ— æ•ˆ: {image_path}")
                            continue
                    
                    messages[0]["content"] = user_content
                else:
                    # ç¬¬ä¸€æ¡æ¶ˆæ¯å·²ç»åŒ…å«å›¾ç‰‡ï¼Œä¸å†é‡å¤æ·»åŠ 
                    logging.debug("ç¬¬ä¸€æ¡æ¶ˆæ¯å·²ç»åŒ…å«å›¾ç‰‡ï¼Œè·³è¿‡é‡å¤æ·»åŠ ")
    else:
        # æ„å»ºå•æ¡æ¶ˆæ¯ï¼ˆåŸæœ‰é€»è¾‘ï¼‰
        if prompt is None:
            raise ValueError("å¿…é¡»æä¾› prompt æˆ– messages å‚æ•°")
        
        user_content = []
        
        # æ·»åŠ æ‰€æœ‰å›¾ç‰‡ï¼ˆæ”¯æŒå¤šå›¾è¾“å…¥ï¼Œæ•°ç»„ä¸­çš„æ‰€æœ‰å›¾ç‰‡éƒ½ä¼šè¢«æ·»åŠ åˆ°æ¶ˆæ¯ä¸­ï¼‰
        if image_paths:
            # ç¡®å®šå›¾ç‰‡å‹ç¼©è®¾ç½®ï¼ˆä½¿ç”¨å…¬å…±å‡½æ•°ï¼‰
            # promptåœºæ™¯é€šå¸¸æ˜¯å•è½®å¯¹è¯
            should_compress, max_longest_side, quality = _determine_image_compression_settings(
                image_paths=image_paths,
                is_multi_round=False
            )
            
            logging.debug(f"å‡†å¤‡æ·»åŠ  {len(image_paths)} å¼ å›¾ç‰‡åˆ°æ¶ˆæ¯ä¸­")
            for image_path in image_paths:
                # åˆ¤æ–­æ˜¯URLè¿˜æ˜¯æœ¬åœ°è·¯å¾„
                if image_path.startswith(("http://", "https://")):
                    # URLæ ¼å¼ï¼Œç›´æ¥ä½¿ç”¨
                    user_content.append({
                        "type": "image_url",
                        "image_url": {"url": image_path}
                    })
                elif os.path.exists(image_path):
                    # æœ¬åœ°æ–‡ä»¶ï¼Œç¼–ç ä¸ºbase64
                    # å¦‚æœå‹ç¼©ï¼Œå¼ºåˆ¶ä½¿ç”¨ JPEG æ ¼å¼ï¼›å¦‚æœä¸å‹ç¼©ï¼Œä¿æŒåŸæ ¼å¼
                    if should_compress:
                        image_format = 'jpeg'
                    else:
                        image_format = get_image_format(image_path)
                    base64_image = encode_image(image_path, compress=should_compress, max_longest_side=max_longest_side, quality=quality)
                    user_content.append({
                        "type": "image_url",
                        "image_url": {"url": f"data:image/{image_format};base64,{base64_image}"}
                    })
                else:
                    logging.warning(f"å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨æˆ–URLæ— æ•ˆï¼Œå·²è·³è¿‡: {image_path}")
                    continue
        
        # æ·»åŠ æ–‡æœ¬æç¤ºè¯
        user_content.append({"type": "text", "text": prompt})
        
        messages = [{"role": "user", "content": user_content}]
    
    # æ„å»ºAPIè°ƒç”¨å‚æ•°
    # æ³¨æ„ï¼štimeout å·²ç»åœ¨å®¢æˆ·ç«¯åˆå§‹åŒ–æ—¶è®¾ç½®ï¼Œä¸éœ€è¦åœ¨ api_params ä¸­ä¼ é€’

    api_params = {
        "model": api_config["model"],
        "messages": messages,
        "max_tokens": api_config.get("max_tokens", 8192),
    }

    # å¯é€‰å‚æ•°ï¼šåªåœ¨ config ä¸­å­˜åœ¨æ—¶æ‰æ·»åŠ ï¼ˆä¸ module2 ä¿æŒä¸€è‡´é£æ ¼ï¼‰
    if "temperature" in api_config:
        api_params["temperature"] = api_config["temperature"]
    if "top_p" in api_config:
        api_params["top_p"] = api_config["top_p"]
    if "frequency_penalty" in api_config:
        api_params["frequency_penalty"] = api_config["frequency_penalty"]
    if "presence_penalty" in api_config:
        api_params["presence_penalty"] = api_config["presence_penalty"]
    if "stream" in api_config:
        api_params["stream"] = api_config["stream"]

    # å¤„ç† extra_bodyï¼ˆæŸäº›APIçš„ç‰¹æ®Šå‚æ•°ï¼Œæ¯”å¦‚æ€è€ƒæ¨¡å¼ enable_thinking ç­‰ï¼‰
    # åœ¨ config ä¸­ï¼Œæˆ‘ä»¬å·²ç»æŠŠæ‰€æœ‰ã€Œéæ ‡å‡†é¡¶å±‚å‚æ•°ã€è‡ªåŠ¨åˆå¹¶è¿›äº† extra_bodyï¼Œ
    # è¿™é‡Œç›´æ¥æ•´ä½“é€ä¼ å³å¯ï¼Œå…¼å®¹å•è½® / å¤šè½®ã€‚
    extra_body = api_config.get("extra_body", {})
    if extra_body:
        api_params["extra_body"] = extra_body
    
    # é‡è¯•æœºåˆ¶
    last_error = None
    for attempt in range(max_retries):
        try:
            # è®°å½•APIè°ƒç”¨ä¿¡æ¯ï¼ˆç”¨äºè°ƒè¯•ï¼‰
            if attempt == 0:
                logging.info(f"ğŸ“¡ å¼€å§‹è°ƒç”¨æ¨¡å‹API: {model_name} (base_url: {api_config['base_url']}, timeout: {timeout}s)")
            else:
                logging.info(f"ğŸ“¡ é‡è¯•è°ƒç”¨æ¨¡å‹API: {model_name} (å°è¯• {attempt + 1}/{max_retries})")
            
            start_time = time.time()
            response = client.chat.completions.create(**api_params)
            response_time = time.time() - start_time
            
            logging.info(f"âœ… APIè°ƒç”¨æˆåŠŸ: {model_name} (è€—æ—¶: {response_time:.2f}s)")
            
            if not response.choices or len(response.choices) == 0:
                # åœ¨è¯¦ç»†æ¨¡å¼ä¸‹ï¼Œè®°å½•å®Œæ•´çš„APIå“åº”ä»¥ä¾¿è°ƒè¯•
                log_mode = os.getenv("EVAL_LOG_MODE", "detailed")
                if log_mode.lower() == "detailed":
                    try:
                        # å°è¯•å°†å“åº”å¯¹è±¡è½¬æ¢ä¸ºå­—å…¸
                        if hasattr(response, "model_dump"):
                            response_dict = response.model_dump()
                        elif hasattr(response, "dict"):
                            response_dict = response.dict()
                        elif isinstance(response, dict):
                            response_dict = response
                        else:
                            # æ‰‹åŠ¨æ„å»ºå“åº”å­—å…¸ï¼Œè·å–å¸¸è§å±æ€§
                            response_dict = {}
                            common_attrs = ['id', 'object', 'created', 'model', 'choices', 'usage', 'system_fingerprint', 'error']
                            for attr in common_attrs:
                                if hasattr(response, attr):
                                    try:
                                        value = getattr(response, attr)
                                        # å°è¯•åºåˆ—åŒ–
                                        try:
                                            json.dumps(value, default=str)
                                            response_dict[attr] = value
                                        except (TypeError, ValueError):
                                            response_dict[attr] = str(value)
                                    except Exception:
                                        pass
                            
                            # å¦‚æœè¿˜æ˜¯æ²¡æœ‰è·å–åˆ°å†…å®¹ï¼Œå°è¯•è·å–æ‰€æœ‰å…¬å…±å±æ€§
                            if not response_dict:
                                for attr in dir(response):
                                    if not attr.startswith('_') and not callable(getattr(response, attr, None)):
                                        try:
                                            value = getattr(response, attr, None)
                                            if value is not None:
                                                try:
                                                    json.dumps(value, default=str)
                                                    response_dict[attr] = value
                                                except (TypeError, ValueError):
                                                    response_dict[attr] = str(value)
                                        except Exception:
                                            pass
                        
                        # è®°å½•å®Œæ•´çš„å“åº”å†…å®¹
                        response_json = json.dumps(response_dict, ensure_ascii=False, indent=2, default=str)
                        logging.error(f"âš ï¸ APIå“åº”ä¸­æ²¡æœ‰choiceså­—æ®µï¼Œå®Œæ•´å“åº”å†…å®¹ï¼š\n{response_json}")
                    except Exception as log_error:
                        logging.error(f"âš ï¸ APIå“åº”ä¸­æ²¡æœ‰choiceså­—æ®µï¼Œä¸”æ— æ³•åºåˆ—åŒ–å“åº”å¯¹è±¡: {log_error}")
                        logging.error(f"å“åº”å¯¹è±¡ç±»å‹: {type(response)}")
                        # å°è¯•è‡³å°‘è®°å½•ä¸€äº›åŸºæœ¬ä¿¡æ¯
                        try:
                            if hasattr(response, 'id'):
                                logging.error(f"å“åº”ID: {response.id}")
                            if hasattr(response, 'model'):
                                logging.error(f"å“åº”æ¨¡å‹: {response.model}")
                            if hasattr(response, 'error'):
                                logging.error(f"å“åº”é”™è¯¯: {response.error}")
                        except Exception:
                            pass
                raise ValueError("APIå“åº”ä¸­æ²¡æœ‰choiceså­—æ®µ")
            
            answer = response.choices[0].message.content
            if not answer:
                raise ValueError("APIå“åº”å†…å®¹ä¸ºç©º")
            
            # æå–tokenä½¿ç”¨ä¿¡æ¯
            prompt_tokens = None
            completion_tokens = None
            total_tokens = None
            if hasattr(response, 'usage') and response.usage:
                prompt_tokens = getattr(response.usage, 'prompt_tokens', None)
                completion_tokens = getattr(response.usage, 'completion_tokens', None)
                total_tokens = getattr(response.usage, 'total_tokens', None)
            
            # æ‰“å°tokenä½¿ç”¨ä¿¡æ¯åˆ°ç»ˆç«¯æ—¥å¿—
            if prompt_tokens is not None or completion_tokens is not None or total_tokens is not None:
                token_info = []
                if prompt_tokens is not None:
                    token_info.append(f"è¾“å…¥token={prompt_tokens}")
                if completion_tokens is not None:
                    token_info.append(f"è¾“å‡ºtoken={completion_tokens}")
                if total_tokens is not None:
                    token_info.append(f"æ€»token={total_tokens}")
                logging.info(f"ğŸ“Š Tokenä½¿ç”¨: {', '.join(token_info)}")
            
            # ä¿å­˜å®Œæ•´çš„åŸå§‹å“åº”ï¼ˆç”¨äºè¯¦ç»†æ—¥å¿—ï¼‰
            try:
                if hasattr(response, "model_dump"):
                    raw_response = response.model_dump()
                elif isinstance(response, dict):
                    raw_response = response
                else:
                    # æ‰‹åŠ¨æ„å»ºå®Œæ•´å“åº”å­—å…¸
                    raw_response = {
                        "id": getattr(response, "id", None),
                        "object": getattr(response, "object", None),
                        "created": getattr(response, "created", None),
                        "model": getattr(response, "model", None),
                        "usage": {
                            "prompt_tokens": prompt_tokens,
                            "completion_tokens": completion_tokens,
                            "total_tokens": total_tokens,
                        } if (prompt_tokens is not None or completion_tokens is not None or total_tokens is not None) else None,
                    }
                    if hasattr(response, "choices") and len(response.choices) > 0:
                        choice = response.choices[0]
                        choice_dict = {
                            "index": getattr(choice, "index", None),
                            "finish_reason": getattr(choice, "finish_reason", None),
                        }
                        if hasattr(choice, "message"):
                            message = choice.message
                            message_dict = {
                                "role": getattr(message, "role", None),
                                "content": getattr(message, "content", None),
                            }
                            # è¯¦ç»†æ—¥å¿—æ¨¡å¼ä¸‹ï¼šä¿ç•™æ‰€æœ‰reasoningå­—æ®µï¼Œä¸æŒ‰ä¼˜å…ˆçº§è¿‡æ»¤
                            # è¿™æ ·è¯¦ç»†æ—¥å¿—å¯ä»¥æ˜¾ç¤ºæ‰€æœ‰æ€è€ƒå†…å®¹
                            if hasattr(message, "reasoning") and getattr(message, "reasoning", None):
                                message_dict["reasoning"] = getattr(message, "reasoning")
                            if hasattr(message, "reasoning_content") and getattr(message, "reasoning_content", None):
                                message_dict["reasoning_content"] = getattr(message, "reasoning_content")
                            if hasattr(message, "reasoning_details") and getattr(message, "reasoning_details", None):
                                message_dict["reasoning_details"] = getattr(message, "reasoning_details")
                            choice_dict["message"] = message_dict
                        raw_response["choices"] = [choice_dict]
            except Exception as e:
                logging.warning(f"æ— æ³•åºåˆ—åŒ–å®Œæ•´å“åº”å¯¹è±¡: {e}")
                # é™çº§ï¼šåªä¿å­˜åŸºæœ¬ä¿¡æ¯
                raw_response = {
                    "model": response.model if hasattr(response, 'model') else None,
                    "usage": {
                        "prompt_tokens": prompt_tokens,
                        "completion_tokens": completion_tokens,
                        "total_tokens": total_tokens,
                    } if (prompt_tokens is not None or completion_tokens is not None or total_tokens is not None) else None
                }
            
            return answer, response_time, raw_response
            
        except Exception as e:
            last_error = e
            # è®°å½•è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯ï¼ˆç”¨äºè°ƒè¯•ï¼‰
            error_type = type(e).__name__
            error_msg = str(e)
            logging.error(f"âŒ APIè°ƒç”¨å¼‚å¸¸: {error_type} - {error_msg}")
            
            # å¦‚æœæ˜¯è¿æ¥ç›¸å…³é”™è¯¯ï¼Œè®°å½•æ›´å¤šä¿¡æ¯
            if "timeout" in error_msg.lower() or "connection" in error_msg.lower():
                logging.error(f"   è¿æ¥ä¿¡æ¯: base_url={api_config['base_url']}, timeout={timeout}s")
            elif "Invalid HTTP request" in error_msg or "400" in error_msg or "Bad Request" in error_msg:
                logging.error(f"   è¯·æ±‚å‚æ•°: model={api_config['model']}, messagesæ•°é‡={len(messages)}")
                logging.error(f"   å¯èƒ½æ˜¯è¯·æ±‚æ ¼å¼é—®é¢˜ï¼Œè¯·æ£€æŸ¥ extra_body å’Œå…¶ä»–å‚æ•°")
            
            if attempt < max_retries - 1:
                wait_time = retry_delay * (2 ** attempt)  # æŒ‡æ•°é€€é¿
                logging.warning(f"APIè°ƒç”¨å¤±è´¥ï¼ˆå°è¯• {attempt + 1}/{max_retries}ï¼‰: {e}ï¼Œ{wait_time:.1f}ç§’åé‡è¯•...")
                time.sleep(wait_time)
            else:
                logging.error(f"APIè°ƒç”¨å¤±è´¥ï¼ˆå·²é‡è¯• {max_retries} æ¬¡ï¼‰: {e}")
                raise
    
    # å¦‚æœæ‰€æœ‰é‡è¯•éƒ½å¤±è´¥
    raise Exception(f"APIè°ƒç”¨å¤±è´¥: {last_error}")


def extract_boxed_content(text: str) -> Optional[str]:
    """
    ä»æ–‡æœ¬ä¸­æå– \\boxed{} ä¸­çš„å†…å®¹ï¼Œæ”¯æŒåµŒå¥—å¤§æ‹¬å·
    
    Args:
        text: è¾“å…¥æ–‡æœ¬
        
    Returns:
        æå–çš„å†…å®¹ï¼Œå¦‚æœæœªæ‰¾åˆ°åˆ™è¿”å› None
    """
    # æ‰‹åŠ¨æŸ¥æ‰¾æ‰€æœ‰ \\boxed{ ... } é…å¯¹ï¼Œæ”¯æŒåµŒå¥—å¤§æ‹¬å·
    all_matches = []
    pos = 0
    
    while True:
        # æŸ¥æ‰¾ä¸‹ä¸€ä¸ª \\boxed{
        start_idx = text.find('\\boxed{', pos)
        if start_idx == -1:
            break
        
        # ä» \\boxed{ åé¢å¼€å§‹åŒ¹é…å¤§æ‹¬å·
        brace_start = start_idx + len('\\boxed{')
        depth = 0
        end_idx = -1
        
        for i in range(brace_start, len(text)):
            if text[i] == '{':
                depth += 1
            elif text[i] == '}':
                if depth == 0:
                    # æ‰¾åˆ°åŒ¹é…çš„å³å¤§æ‹¬å·
                    end_idx = i
                    break
                else:
                    depth -= 1
        
        if end_idx != -1:
            # æå–å†…å®¹
            content = text[brace_start:end_idx].strip()
            if content:
                all_matches.append(content)
            pos = end_idx + 1
        else:
            # æœªæ‰¾åˆ°åŒ¹é…çš„å³å¤§æ‹¬å·ï¼Œè·³è¿‡è¿™ä¸ª \\boxed{
            pos = brace_start
    
    # è¿”å›æœ€åä¸€ä¸ªåŒ¹é…ï¼ˆé€šå¸¸æ˜¯æœ€ç»ˆç­”æ¡ˆï¼‰
    return all_matches[-1] if all_matches else None


def extract_json_from_text(text: str) -> Dict[str, Any]:
    """
    ä»æ–‡æœ¬ä¸­æå–JSONå¯¹è±¡ï¼ˆå‚è€ƒ model1.pyï¼‰
    
    Args:
        text: è¾“å…¥æ–‡æœ¬
        
    Returns:
        æå–çš„JSONå­—å…¸ï¼Œå¦‚æœæœªæ‰¾åˆ°åˆ™è¿”å›ç©ºå­—å…¸
    """
    text = text.strip()
    # å°è¯•åŒ¹é… ```json {...} ``` æˆ– {...}
    pattern = r"```json\s*(\{.*?\})\s*```|(\{.*\})"
    match = re.search(pattern, text, re.DOTALL)
    if match:
        json_str = match.group(1) or match.group(2)
        try:
            return json.loads(json_str)
        except:
            pass
    
    # å¦‚æœæ²¡æ‰¾åˆ°ä»£ç å—ï¼Œå°è¯•ç›´æ¥å¯»æ‰¾JSON
    start = text.find('{')
    end = text.rfind('}')
    if start != -1 and end != -1:
        try:
            return json.loads(text[start:end+1])
        except:
            pass
    
    return {}


def extract_answer_by_keywords(text: str) -> Optional[str]:
    """
    é€šè¿‡å…³é”®è¯æ¨¡å¼æå–ç­”æ¡ˆï¼ˆå‚è€ƒ model1.pyï¼‰
    
    Args:
        text: è¾“å…¥æ–‡æœ¬
        
    Returns:
        æå–çš„ç­”æ¡ˆï¼Œå¦‚æœæœªæ‰¾åˆ°åˆ™è¿”å› None
    """
    # æŸ¥æ‰¾ "ç­”æ¡ˆæ˜¯"ã€"ç­”æ¡ˆï¼š"ã€"Answer:" ç­‰å…³é”®è¯åçš„å†…å®¹
    answer_patterns = [
        r'ç­”æ¡ˆæ˜¯[ï¼š:]\s*(.+?)(?:\n|$)',
        r'ç­”æ¡ˆ[ï¼š:]\s*(.+?)(?:\n|$)',
        r'Answer[ï¼š:]\s*(.+?)(?:\n|$)',
        r'æœ€ç»ˆç­”æ¡ˆ[ï¼š:]\s*(.+?)(?:\n|$)',
        r'ç­”æ¡ˆä¸º[ï¼š:]\s*(.+?)(?:\n|$)',
        r'ç­”æ¡ˆæ˜¯\s*(.+?)(?:\n|$)',
    ]
    for pattern in answer_patterns:
        match = re.search(pattern, text, re.IGNORECASE)
        if match:
            answer_content = match.group(1).strip()
            # æ¸…ç†å¯èƒ½çš„æ ‡ç‚¹ç¬¦å·
            answer_content = answer_content.rstrip('ã€‚ï¼Œ,')
            if answer_content:
                return answer_content
    return None


def truncate_last_n_tokens(text: str, n_tokens: int = 100) -> str:
    """
    æˆªå–æ–‡æœ¬çš„æœ€å N ä¸ª token
    
    Args:
        text: è¾“å…¥æ–‡æœ¬
        n_tokens: è¦æˆªå–çš„ token æ•°é‡ï¼Œé»˜è®¤ 100
        
    Returns:
        æˆªå–åçš„æ–‡æœ¬ï¼ˆæœ€å N ä¸ª tokenï¼‰
    """
    if not text:
        return ""
    
    # ä¼°ç®—æ€» token æ•°
    total_tokens = estimate_text_tokens(text)
    
    # å¦‚æœæ–‡æœ¬çš„ token æ•°å°äºç­‰äºç›®æ ‡ token æ•°ï¼Œç›´æ¥è¿”å›
    if total_tokens <= n_tokens:
        return text
    
    # è®¡ç®—éœ€è¦æˆªå–çš„å­—ç¬¦æ•°ï¼ˆä¿å®ˆä¼°è®¡ï¼š1 token â‰ˆ 4 å­—ç¬¦ï¼‰
    # ä¸ºäº†ç¡®ä¿èƒ½æˆªå–åˆ°è¶³å¤Ÿçš„ tokenï¼Œæˆ‘ä»¬ä½¿ç”¨æ›´ä¿å®ˆçš„ä¼°ç®—
    target_chars = n_tokens * 4
    
    # ä»æœ«å°¾æˆªå–
    truncated = text[-target_chars:]
    
    # å¦‚æœæˆªå–åçš„ token æ•°ä»ç„¶è¶…è¿‡ç›®æ ‡ï¼Œç»§ç»­è°ƒæ•´
    while estimate_text_tokens(truncated) > n_tokens and len(truncated) > 0:
        # æ¯æ¬¡å‡å°‘ 10% çš„å­—ç¬¦
        truncated = truncated[int(len(truncated) * 0.9):]
    
    return truncated


def extract_answer_from_response(response: str, has_options: bool = False) -> tuple:
    """
    ä»æ¨¡å‹å“åº”ä¸­æå–ç­”æ¡ˆï¼ˆå‚è€ƒ model1.py çš„å¤šå±‚ fallback æœºåˆ¶ï¼‰
    
    æå–ç­–ç•¥ï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰ï¼š
    1. ä» \\boxed{} ä¸­æå–ï¼ˆæ”¯æŒåµŒå¥—å¤§æ‹¬å·ï¼‰
    2. ä» JSON æ ¼å¼ä¸­æå–ï¼ˆå…¼å®¹æ—§æ ¼å¼ï¼‰
    3. å¦‚æœ box ä¸ºç©ºï¼Œä½¿ç”¨ content çš„æœ€åä¸€ç™¾ä¸ª token æˆªæ–­
    4. å¦‚æœéƒ½æ²¡æœ‰ï¼Œè¿”å›å®Œæ•´å“åº”ï¼ˆä¿åº•æœºåˆ¶ï¼‰
    
    Args:
        response: æ¨¡å‹åŸå§‹å“åº”
        has_options: æ˜¯å¦æ˜¯é€‰æ‹©é¢˜ï¼ˆä¿ç•™å‚æ•°ä»¥å…¼å®¹ç°æœ‰è°ƒç”¨ï¼Œä½†ä¸å†ä½¿ç”¨ï¼‰
        
    Returns:
        (extracted_answer, is_from_box, original_response)
        - extracted_answer: æå–çš„ç­”æ¡ˆ
        - is_from_box: æ˜¯å¦ä» \\boxed{} ä¸­æå–ï¼ˆTrueè¡¨ç¤ºä»boxä¸­æå–ï¼ŒFalseè¡¨ç¤ºä½¿ç”¨å®Œæ•´å“åº”ï¼‰
        - original_response: åŸå§‹å®Œæ•´å“åº”ï¼ˆç”¨äºfallbackï¼‰
    """
    original_response = response.strip()
    response = original_response
    
    # ==================== ç­–ç•¥1: ä» \\boxed{} ä¸­æå–ï¼ˆæ”¯æŒåµŒå¥—å¤§æ‹¬å·ï¼‰ ====================
    boxed_content = extract_boxed_content(response)
    if boxed_content:
        # ä» box ä¸­æˆåŠŸæå–åˆ°å†…å®¹
        logging.debug(f"ä» \\boxed{{}} ä¸­æå–åˆ°ç­”æ¡ˆ: {boxed_content[:100]}")
        return boxed_content, True, original_response
    
    # ==================== ç­–ç•¥2: ä» JSON æ ¼å¼ä¸­æå–ï¼ˆå…¼å®¹æ—§æ ¼å¼ï¼‰ ====================
    result_json = extract_json_from_text(response)
    if result_json:
        answer_wrapped = result_json.get("answer", "")
        if answer_wrapped:
            # å°è¯•ä» JSON çš„ answer å­—æ®µä¸­æå– boxed æ ¼å¼
            answer_from_json_box = extract_boxed_content(answer_wrapped)
            if answer_from_json_box:
                logging.debug(f"ä» JSON æ ¼å¼çš„ \\boxed{{}} ä¸­æå–åˆ°ç­”æ¡ˆ: {answer_from_json_box[:100]}")
                return answer_from_json_box, True, original_response
            else:
                # å¦‚æœæ²¡æœ‰ boxed æ ¼å¼ï¼Œç›´æ¥ä½¿ç”¨ answer å†…å®¹
                answer_cleaned = answer_wrapped.strip()
                if answer_cleaned:
                    logging.debug(f"ä» JSON æ ¼å¼ä¸­æå–åˆ°ç­”æ¡ˆ: {answer_cleaned[:100]}")
                    return answer_cleaned, False, original_response
    
    # ==================== ç­–ç•¥3: å¦‚æœ box ä¸ºç©ºï¼Œä½¿ç”¨ content çš„æœ€åä¸€ç™¾ä¸ª token æˆªæ–­ ====================
    # å¦‚æœæ‰§è¡Œåˆ°è¿™é‡Œï¼Œè¯´æ˜å‰é¢çš„ç­–ç•¥éƒ½æ²¡æœ‰ä» box ä¸­æå–åˆ°å†…å®¹ï¼ˆbox ä¸ºç©ºï¼‰
    # ä½¿ç”¨æœ€å100ä¸ªtokenæˆªæ–­ä½œä¸ºè¾“å…¥ç»™è£åˆ¤æ¨¡å‹
    truncated_content = truncate_last_n_tokens(original_response, n_tokens=100)
    if truncated_content and truncated_content.strip():
        logging.debug(f"Boxä¸ºç©ºï¼Œä½¿ç”¨æœ€å100ä¸ªtokenæˆªæ–­: {truncated_content[:100]}...")
        return truncated_content, False, original_response
    
    # ==================== ç­–ç•¥4: å¦‚æœéƒ½æ²¡æœ‰æå–åˆ°ï¼Œè¿”å›å®Œæ•´å“åº”ï¼ˆä¿åº•æœºåˆ¶ï¼‰ ====================
    logging.debug("æœªèƒ½ä»ä»»ä½•ç­–ç•¥ä¸­æå–åˆ°ç­”æ¡ˆï¼Œä½¿ç”¨å®Œæ•´å“åº”ä½œä¸ºä¿åº•")
    return original_response, False, original_response
