"""
ç»“æœè½¬æ¢å’Œä¿å­˜æ¨¡å—
è´Ÿè´£å°†è¯„æµ‹ç»“æœè½¬æ¢ä¸ºmodule2æ ¼å¼å¹¶ä¿å­˜åˆ°æ–‡ä»¶
"""
import json
import logging
from pathlib import Path
from typing import Dict, Any, List, Optional
from .result_utils import build_process_value
from .statistics import calculate_output_statistics


def convert_to_module2_format(
    result: Dict[str, Any],
    model_name: str,
    profile: str
) -> Optional[Dict[str, Any]]:
    """
    å°†å•ä¸ªè¯„æµ‹ç»“æœè½¬æ¢ä¸ºmodule2æ ¼å¼
    
    Args:
        result: è¯„æµ‹ç»“æœå­—å…¸
        model_name: æ¨¡å‹åç§°
        profile: ç”¨æˆ·ç”»åƒ
        
    Returns:
        module2æ ¼å¼çš„ç»“æœé¡¹ï¼Œå¦‚æœè½¬æ¢å¤±è´¥è¿”å›None
    """
    profile_data = result.get("profiles", {}).get(profile, {})
    model_data = profile_data.get("models", {}).get(model_name, {})
    
    if not model_data:
        return None
    
    # ç»Ÿä¸€ä½¿ç”¨"model"ä½œä¸ºæ¨¡å‹é”®ï¼ˆå› ä¸ºä¸€ä¸ªæ–‡ä»¶åªæœ‰ä¸€ä¸ªæ¨¡å‹çš„è¾“å‡ºï¼‰
    model_key = "model"
    
    # è·å–æ¨¡å‹ç­”æ¡ˆå’Œæ¨ç†è¿‡ç¨‹ï¼ˆå•è½®é¢˜ç›®ä½¿ç”¨ï¼‰
    model_answer = model_data.get("model_answer", "")
    extracted_answer = model_data.get("extracted_answer", "")
    is_multi_round = result.get("is_multi_round", False)
    
    # å¤„ç†å¤šè½®é—®ç­”
    rounds_list = model_data.get("rounds", [])
    
    # è°ƒè¯•ï¼šæ£€æŸ¥æ•°æ®ä¼ é€’
    if is_multi_round:
        logging.info(f"ğŸ” convert_to_module2_format: question_id={result.get('question_id', '')}, is_multi_round={is_multi_round}")
        logging.info(f"ğŸ” model_data.keys()={list(model_data.keys())}, has_rounds={'rounds' in model_data}")
        logging.info(f"ğŸ” rounds_listç±»å‹={type(rounds_list)}, rounds_listé•¿åº¦={len(rounds_list) if isinstance(rounds_list, list) else 0}")
        if isinstance(rounds_list, list) and len(rounds_list) > 0:
            logging.info(f"ğŸ” rounds_listå‰2é¡¹: {[r.get('round', 'NO_ROUND') for r in rounds_list[:2]]}")
        elif 'rounds' in model_data:
            logging.warning(f"âš ï¸ roundså­—æ®µå­˜åœ¨ä½†å€¼ä¸º: {type(model_data['rounds'])}, å†…å®¹: {str(model_data['rounds'])[:200]}")
    
    if is_multi_round and isinstance(rounds_list, list) and len(rounds_list) > 0:
        # å¤šè½®é¢˜ç›®ï¼šæŒ‰ round åˆ†å¼€ä¿å­˜
        answer_dict = {}
        process_dict = {}
        match_gt_dict = {}  # å¤šè½®é¢˜ç›®ï¼šæŒ‰è½®æ¬¡è®°å½•æ­£ç¡®æ€§
        judge_reasoning_dict = {}  # å¤šè½®é¢˜ç›®ï¼šæŒ‰è½®æ¬¡è®°å½•è£åˆ¤æ¨ç†
        
        for round_data in rounds_list:
            round_key = round_data.get("round", "")
            if not round_key:
                # å°è¯•ä»å…¶ä»–å­—æ®µè·å– round_key
                if "question" in round_data:
                    # å°è¯•ä» question å­—æ®µæ¨æ–­ï¼ˆå¦‚æœ question æ˜¯å­—å…¸ï¼Œå–ç¬¬ä¸€ä¸ª keyï¼‰
                    q = round_data.get("question", "")
                    if isinstance(q, dict):
                        round_key = list(q.keys())[0] if q else ""
                    elif isinstance(q, str) and "round" in str(round_data):
                        # å°è¯•ä»å…¶ä»–å­—æ®µæ¨æ–­
                        for key in round_data.keys():
                            if "round" in str(key).lower():
                                round_key = str(key)
                                break
            
            if round_key:
                # å¦‚æœå­˜åœ¨errorå­—æ®µï¼Œç¡®ä¿answerç›¸å…³å­—æ®µéƒ½ä¸ºç©ºï¼Œä¸ä¼ å…¥é”™è¯¯ä¿¡æ¯
                if "error" in round_data:
                    round_answer = ""
                    round_process = ""
                    round_correct = False
                    round_reasoning = ""
                else:
                    # æå–æ¯è½®çš„ç­”æ¡ˆå’Œè¿‡ç¨‹
                    round_answer = round_data.get("extracted_answer", "")
                    # ä½¿ç”¨æ€è€ƒå†…å®¹ + å»æ‰ boxed çš„æ­£æ–‡ ä½œä¸º process
                    raw_round_answer = round_data.get("model_answer", "") or round_data.get("process", "")
                    round_process = build_process_value(raw_round_answer, round_data)
                    round_correct = round_data.get("is_correct", False)
                    round_reasoning = round_data.get("reasoning", "")  # æå–è£åˆ¤æ¨ç†
                    
                    # å¦‚æœ extracted_answer ä¸ºç©ºï¼Œå°è¯•ä»å…¶ä»–å­—æ®µè·å–
                    if not round_answer:
                        round_answer = round_data.get("answer", "")
                
                answer_dict[round_key] = round_answer
                process_dict[round_key] = round_process
                match_gt_dict[round_key] = round_correct
                judge_reasoning_dict[round_key] = round_reasoning
                logging.info(f"âœ… æå–è½®æ¬¡ {round_key}: answeré•¿åº¦={len(round_answer) if round_answer else 0}, processé•¿åº¦={len(round_process) if round_process else 0}, correct={round_correct}")
            else:
                logging.warning(f"âš ï¸ è½®æ¬¡æ•°æ®ç¼ºå°‘ round å­—æ®µ: {list(round_data.keys())}")
        
        # ç¡®ä¿å­—å…¸ä¸ä¸ºç©º
        if answer_dict and len(answer_dict) > 0:
            model_answer_value = answer_dict
            process_value = process_dict
            match_gt_value = match_gt_dict
            judge_reasoning_value = judge_reasoning_dict
            logging.info(f"âœ… å¤šè½®é¢˜ç›® {result.get('question_id', '')} æˆåŠŸè½¬æ¢ä¸ºå­—å…¸æ ¼å¼: {list(answer_dict.keys())}, å…± {len(answer_dict)} è½®")
        else:
            # å¦‚æœæå–å¤±è´¥ï¼Œé™çº§ä¸ºå•è½®æ ¼å¼
            logging.error(f"âŒ å¤šè½®é¢˜ç›® {result.get('question_id', '')} çš„ rounds æ•°æ®æå–å¤±è´¥ï¼rounds_listé•¿åº¦={len(rounds_list) if isinstance(rounds_list, list) else 0}, answer_dicté•¿åº¦={len(answer_dict)}")
            logging.error(f"    rounds_listå†…å®¹: {rounds_list}")
            # å°è¯•ä»æœ€åä¸€è½®è·å–æ•°æ®ï¼ˆé™çº§å¤„ç†ï¼‰
            if isinstance(rounds_list, list) and len(rounds_list) > 0:
                last_round = rounds_list[-1]
                fallback_answer = last_round.get("extracted_answer", "") or last_round.get("answer", "")
                fallback_process = last_round.get("model_answer", "") or last_round.get("process", "")
                fallback_reasoning = last_round.get("reasoning", "")
                logging.warning(f"   é™çº§ï¼šä½¿ç”¨æœ€åä¸€è½®æ•°æ®ä½œä¸ºå•è½®æ ¼å¼")
                model_answer_value = fallback_answer
                process_value = fallback_process
                match_gt_value = last_round.get("is_correct", False)
                judge_reasoning_value = fallback_reasoning
            else:
                # å®Œå…¨é™çº§ä¸ºå•è½®æ ¼å¼
                model_answer_value = extracted_answer if extracted_answer else ""
                process_value = build_process_value(model_answer, model_data)
                match_gt_value = model_data.get("is_correct", False) or model_data.get("all_rounds_correct", False)
                judge_reasoning_value = model_data.get("reasoning", "")
    else:
        # å•è½®é¢˜ç›®ï¼šç­”æ¡ˆä»ç„¶æ˜¯æå–åçš„ answerï¼Œprocess ä½¿ç”¨æ€è€ƒå†…å®¹ + å»æ‰ boxed çš„æ­£æ–‡
        # å¦‚æœå­˜åœ¨errorå­—æ®µï¼Œç¡®ä¿answerç›¸å…³å­—æ®µéƒ½ä¸ºç©ºï¼Œä¸ä¼ å…¥é”™è¯¯ä¿¡æ¯
        if "error" in model_data:
            model_answer_value = ""
            process_value = ""
            match_gt_value = False
            judge_reasoning_value = ""
        else:
            model_answer_value = extracted_answer if extracted_answer else ""
            process_value = build_process_value(model_answer, model_data)
            match_gt_value = model_data.get("is_correct", False) or model_data.get("all_rounds_correct", False)
            judge_reasoning_value = model_data.get("reasoning", "")
    
    # æ„å»ºmodule2æ ¼å¼çš„ç»“æœé¡¹
    # å¤„ç† image_pathï¼šç¡®ä¿å§‹ç»ˆä¸ºæ•°ç»„æ ¼å¼
    image_paths_result = result.get("image_paths", [])
    if not image_paths_result:
        # å¦‚æœæ²¡æœ‰ image_pathsï¼Œå°è¯•ä» image_path è·å–ï¼ˆå¯èƒ½æ˜¯å­—ç¬¦ä¸²æˆ–æ•°ç»„ï¼‰
        image_path_raw = result.get("image_path", "")
        if isinstance(image_path_raw, list):
            image_paths_result = image_path_raw
        elif image_path_raw:
            image_paths_result = [image_path_raw]
        else:
            image_paths_result = []
    
    module2_item = {
        "question_id": result.get("question_id", result.get("id", "")),
        "question": result.get("question", ""),
        "answer": result.get("answer", ""),
        "question_type": result.get("question_type", ""),
        "image_type": result.get("image_type", ""),
        "image_path": image_paths_result,  # ä½¿ç”¨æ•°ç»„æ ¼å¼ä¿å­˜æ‰€æœ‰å›¾ç‰‡è·¯å¾„
        "options": result.get("options"),
        "profile": profile,
    }
    
    # ä¿ç•™åˆ†ç±»å­—æ®µ
    for field in ["scenario", "capability", "difficulty", "source", "language"]:
        if field in result:
            module2_item[field] = result[field]
    
    # ä¿ç•™ original_image_path å­—æ®µï¼ˆç¡®ä¿ä¸ºæ•°ç»„æ ¼å¼ï¼‰
    original_image_path_result = result.get("original_image_path", [])
    if original_image_path_result:
        # å¦‚æœå·²ç»æ˜¯æ•°ç»„ï¼Œç›´æ¥ä½¿ç”¨ï¼›å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œè½¬æ¢ä¸ºæ•°ç»„
        if isinstance(original_image_path_result, list):
            module2_item["original_image_path"] = original_image_path_result
        elif isinstance(original_image_path_result, str):
            module2_item["original_image_path"] = [original_image_path_result] if original_image_path_result else []
    
    # è·å–å“åº”æ—¶é—´ï¼ˆå¤šè½®é¢˜ç›®ä½¿ç”¨ total_response_timeï¼Œå•è½®é¢˜ç›®ä½¿ç”¨ response_timeï¼‰
    if is_multi_round and "total_response_time" in model_data:
        response_time_value = model_data.get("total_response_time", 0.0)
    else:
        response_time_value = model_data.get("response_time", 0.0)
    
    # æ·»åŠ æ¨¡å‹ç»“æœï¼ˆåªä¿å­˜å½“å‰æ¨¡å‹çš„æ•°æ®ï¼Œä¸ä¿å­˜å…¶ä»–æ¨¡å‹çš„æ•°æ®ï¼‰
    module2_item[model_key] = {
        "process": process_value,
        "answer": model_answer_value,
        "model_name": model_name,
        "response_time": response_time_value,
        "match_gt": match_gt_value,  # å¤šè½®é¢˜ç›®ä¸ºå­—å…¸æ ¼å¼ {round1: true/false, round2: true/false}ï¼Œå•è½®é¢˜ç›®ä¸ºå¸ƒå°”å€¼
        "judge_reasoning": judge_reasoning_value  # è£åˆ¤æ¨¡å‹çš„æ¨ç†ï¼šå¤šè½®é¢˜ç›®ä¸ºå­—å…¸æ ¼å¼ {round1: "...", round2: "..."}ï¼Œå•è½®é¢˜ç›®ä¸ºå­—ç¬¦ä¸²
    }
    
    # å¦‚æœæ˜¯å¤šè½®é¢˜ç›®ï¼Œä¿å­˜æ¯è½®çš„æ­£ç¡®æ€§ä¿¡æ¯ï¼ˆç”¨äºæŒ‰è½®æ¬¡ç»Ÿè®¡ï¼Œä¸å½±å“è¾“å‡ºæ ¼å¼ï¼‰
    if is_multi_round and isinstance(model_data.get("rounds"), list):
        rounds_info = []
        for round_data in model_data.get("rounds", []):
            rounds_info.append({
                "round": round_data.get("round", ""),
                "is_correct": round_data.get("is_correct", False)
            })
        module2_item["_rounds_info"] = rounds_info  # éšè—å­—æ®µï¼Œç”¨äºç»Ÿè®¡
    
    # æ·»åŠ comparisonå­—æ®µ
    # å¯¹äºå¤šè½®é¢˜ç›®ï¼Œæ£€æŸ¥æ‰€æœ‰è½®æ¬¡æ˜¯å¦éƒ½æ­£ç¡®ï¼›å¯¹äºå•è½®é¢˜ç›®ï¼Œç›´æ¥ä½¿ç”¨ is_correct
    if is_multi_round and isinstance(match_gt_value, dict):
        # å¤šè½®é¢˜ç›®ï¼šæ‰€æœ‰è½®æ¬¡éƒ½æ­£ç¡®æ‰ç®—æ­£ç¡®
        all_rounds_correct = all(match_gt_value.values()) if match_gt_value else False
        agreement_value = 1 if all_rounds_correct else 0
    else:
        # å•è½®é¢˜ç›®ï¼šç›´æ¥ä½¿ç”¨å¸ƒå°”å€¼
        agreement_value = 1 if match_gt_value else 0
    
    module2_item["comparison"] = {
        "agreement_with_gt": agreement_value
    }
    
    return module2_item


def flush_json_buffer(
    model_name: str,
    profile: str,
    result_buffers: Dict,
    output_files: Dict,
    enabled_models: List[str]
):
    """
    åˆ·æ–°æŒ‡å®šæ¨¡å‹å’Œç”¨æˆ·ç”»åƒçš„JSONæ ¼å¼buffer
    
    Args:
        model_name: æ¨¡å‹åç§°
        profile: ç”¨æˆ·ç”»åƒ
        result_buffers: ç»“æœç¼“å†²åŒºå­—å…¸ {(model_name, profile): list(results)}
        output_files: è¾“å‡ºæ–‡ä»¶å­—å…¸ {(model_name, profile): file_path}
        enabled_models: å¯ç”¨çš„æ¨¡å‹åˆ—è¡¨
    """
    key = (model_name, profile)
    if key not in result_buffers:
        return
    
    buffer = result_buffers[key]
    if not buffer:
        return
    
    output_file = output_files[key]
    
    try:
        # è¯»å–ç°æœ‰æ•°æ®
        existing_data = {"statistics": {}, "results": []}
        if output_file.exists() and output_file.stat().st_size > 0:
            with open(output_file, 'r', encoding='utf-8') as f:
                existing_data = json.load(f)
        
        # ä¿å­˜ç­–ç•¥ï¼šä¿ç•™æ‰€æœ‰è®°å½•ï¼ˆåŒ…æ‹¬é‡å¤çš„ï¼‰ï¼Œç›´æ¥è¿½åŠ æ–°ç»“æœ
        # å»é‡é€»è¾‘åªåœ¨ç»­ä¼ åˆ¤æ–­å’Œç®—åˆ†æ—¶ä½¿ç”¨ï¼Œä¿å­˜æ—¶ä¸åšå»é‡
        existing_results = existing_data.get("results", [])
        
        # ç›´æ¥è¿½åŠ æ–°ç»“æœï¼Œä¸åšå»é‡ï¼ˆå’ŒJSONLæ ¼å¼ä¿æŒä¸€è‡´ï¼‰
        new_results = []
        for item in buffer:
            new_results.append(item)
        
        # åˆå¹¶æ‰€æœ‰ç»“æœï¼ˆä¿ç•™æ‰€æœ‰è®°å½•ï¼ŒåŒ…æ‹¬é‡å¤çš„ï¼‰
        final_results = existing_results + new_results
        
        if new_results:
            # å¦‚æœæœ‰æ–°ç»“æœï¼Œéœ€è¦ä¿å­˜
            existing_data["results"] = final_results
            
            # é‡æ–°è®¡ç®—ç»Ÿè®¡ä¿¡æ¯ï¼ˆç»Ÿè®¡æ—¶ä¼šè‡ªåŠ¨å»é‡ï¼‰
            stats = calculate_output_statistics(final_results, enabled_models)
            existing_data["statistics"] = stats
            
            # åŸå­å†™å…¥ï¼šå…ˆå†™å…¥ä¸´æ—¶æ–‡ä»¶ï¼ŒæˆåŠŸåå†æ›¿æ¢åŸæ–‡ä»¶ï¼ˆé¿å…æ•°æ®ä¸¢å¤±ï¼‰
            temp_file = output_file.with_suffix(output_file.suffix + '.tmp')
            try:
                with open(temp_file, 'w', encoding='utf-8') as f:
                    json.dump(existing_data, f, ensure_ascii=False, indent=2)
                # å†™å…¥æˆåŠŸåå†æ›¿æ¢åŸæ–‡ä»¶ï¼ˆåŸå­æ“ä½œï¼‰
                temp_file.replace(output_file)
                logging.debug(f"æ‰¹é‡ä¿å­˜ {len(new_results)} æ¡æ–°ç»“æœåˆ° {output_file.name} (å…± {len(final_results)} æ¡ç»“æœï¼Œä¿ç•™æ‰€æœ‰è®°å½•)")
                
                # å†™å…¥æˆåŠŸåæ‰æ¸…ç©ºbufferï¼ˆå·²ä¿å­˜çš„ç»“æœå·²å†™å…¥æ–‡ä»¶ï¼‰
                # æ³¨æ„ï¼šä¸åº”è¯¥æŠŠfinal_resultsæ”¾å›bufferï¼Œå¦åˆ™ä¼šå¯¼è‡´ç»“æœé‡å¤ç´¯ç§¯
                result_buffers[key] = []
            except Exception as e:
                logging.error(f"  âŒ å†™å…¥ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}ï¼Œä¿ç•™åŸæ–‡ä»¶ä¸å˜ï¼Œbufferä¿æŒä¸å˜")
                if temp_file.exists():
                    temp_file.unlink()  # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                raise
    except Exception as e:
        logging.error(f"æ‰¹é‡ä¿å­˜å¤±è´¥ ({model_name}, {profile}): {e}")

